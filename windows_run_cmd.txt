countries s3:
python -m code.model.trainer --base_output_dir "output/countries_s3/" --path_length 3 --hidden_size 2 --embedding_size 2 --batch_size 128 --beta 0.1 --Lambda 0.02 --use_entity_embeddings 1 --train_entity_embeddings 0 --train_relation_embeddings 1 --data_input_dir "datasets/data_preprocessed/countries_S3/" --vocab_dir "datasets/data_preprocessed/countries_S3/vocab" --model_load_dir "nothing" --load_model 0 --nell_evaluation 0 --label_gen 0 --learning_rate 1e-4 --total_iterations=100

fb15k:
python -m code.model.trainer --base_output_dir "output/fb15k-237/" --path_length 3 --hidden_size 50 --embedding_size 50 --batch_size 256 --beta 0.02 --Lambda 0.02 --use_entity_embeddings 0 --train_entity_embeddings 0 --train_relation_embeddings 1 --data_input_dir "datasets/data_preprocessed/FB15K-237/" --vocab_dir "datasets/data_preprocessed/FB15K-237/vocab" --model_load_dir "saved_models/fb15k-237" --load_model 0 --nell_evaluation 0 --label_gen 0 --learning_rate 1e-4 --total_iterations=100

--total_iterations is shortened for testing purposes