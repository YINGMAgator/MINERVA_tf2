02/01/2022 09:36:18 PM: [ reading vocab files... ]
02/01/2022 09:36:18 PM: [ Reading mid to name map ]
02/01/2022 09:36:18 PM: [ Done.. ]
02/01/2022 09:36:18 PM: [ Total number of entities 273 ]
02/01/2022 09:36:18 PM: [ Total number of relations 6 ]
02/01/2022 09:36:20 PM: [ <tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.LSTMCell object at 0x0000029D8237EE20>: Note that this cell is not optimized for performance. Please use tf.contrib.cudnn_rnn.CudnnLSTM for better performance on GPU. ]
02/01/2022 09:36:20 PM: [ `tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0. ]
02/01/2022 09:36:21 PM: [ batch_counter:    1, num_hits:  0.0000, avg. reward per batch  0.0000, num_ep_correct    0, avg_ep_correct  0.0000, train loss -0.0051 ]
02/01/2022 09:36:21 PM: [ batch_counter:    2, num_hits:  0.0000, avg. reward per batch  0.0000, num_ep_correct    0, avg_ep_correct  0.0000, train loss -0.0100 ]
02/01/2022 09:36:21 PM: [ batch_counter:    3, num_hits:  0.0000, avg. reward per batch  0.0000, num_ep_correct    0, avg_ep_correct  0.0000, train loss -0.0148 ]
02/01/2022 09:36:22 PM: [ batch_counter:    4, num_hits:  0.0000, avg. reward per batch  0.0000, num_ep_correct    0, avg_ep_correct  0.0000, train loss -0.0195 ]
02/01/2022 09:36:22 PM: [ batch_counter:    5, num_hits:  0.0000, avg. reward per batch  0.0000, num_ep_correct    0, avg_ep_correct  0.0000, train loss -0.0242 ]
02/01/2022 09:36:22 PM: [ batch_counter:    6, num_hits:  0.0000, avg. reward per batch  0.0000, num_ep_correct    0, avg_ep_correct  0.0000, train loss -0.0288 ]
02/01/2022 09:36:23 PM: [ batch_counter:    7, num_hits:  0.0000, avg. reward per batch  0.0000, num_ep_correct    0, avg_ep_correct  0.0000, train loss -0.0333 ]
02/01/2022 09:36:23 PM: [ batch_counter:    8, num_hits:  0.0000, avg. reward per batch  0.0000, num_ep_correct    0, avg_ep_correct  0.0000, train loss -0.0376 ]
02/01/2022 09:36:23 PM: [ batch_counter:    9, num_hits:  0.0000, avg. reward per batch  0.0000, num_ep_correct    0, avg_ep_correct  0.0000, train loss -0.0419 ]
02/01/2022 09:36:23 PM: [ batch_counter:   10, num_hits:  0.0000, avg. reward per batch  0.0000, num_ep_correct    0, avg_ep_correct  0.0000, train loss -0.0462 ]
02/01/2022 09:36:24 PM: [ batch_counter:   11, num_hits:  0.0000, avg. reward per batch  0.0000, num_ep_correct    0, avg_ep_correct  0.0000, train loss -0.0503 ]
02/01/2022 09:36:24 PM: [ batch_counter:   12, num_hits:  0.0000, avg. reward per batch  0.0000, num_ep_correct    0, avg_ep_correct  0.0000, train loss -0.0544 ]
02/01/2022 09:36:24 PM: [ batch_counter:   13, num_hits:  0.0000, avg. reward per batch  0.0000, num_ep_correct    0, avg_ep_correct  0.0000, train loss -0.0584 ]
02/01/2022 09:36:25 PM: [ batch_counter:   14, num_hits:  0.0000, avg. reward per batch  0.0000, num_ep_correct    0, avg_ep_correct  0.0000, train loss -0.0623 ]
02/01/2022 09:36:25 PM: [ batch_counter:   15, num_hits:  0.0000, avg. reward per batch  0.0000, num_ep_correct    0, avg_ep_correct  0.0000, train loss -0.0661 ]
02/01/2022 09:36:25 PM: [ batch_counter:   16, num_hits:  0.0000, avg. reward per batch  0.0000, num_ep_correct    0, avg_ep_correct  0.0000, train loss -0.0698 ]
02/01/2022 09:36:25 PM: [ batch_counter:   17, num_hits:  0.0000, avg. reward per batch  0.0000, num_ep_correct    0, avg_ep_correct  0.0000, train loss -0.0735 ]
02/01/2022 09:36:26 PM: [ batch_counter:   18, num_hits:  0.0000, avg. reward per batch  0.0000, num_ep_correct    0, avg_ep_correct  0.0000, train loss -0.0770 ]
02/01/2022 09:36:26 PM: [ batch_counter:   19, num_hits:  0.0000, avg. reward per batch  0.0000, num_ep_correct    0, avg_ep_correct  0.0000, train loss -0.0806 ]
